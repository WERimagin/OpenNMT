文そのまま（答えや疑問詞など含めず）
質問文の文字数が5以下のノイズデータは省いたが、それ以外の文は全て使用した。
50文字までを訓練に使用

全ての文
0.40700896414178056
0.23134561150951782
0.15074457485064752
0.10203992991167184

Duらの論文を参考に、内容語の重複がないものを取り除く
疑問詞がないものも取り除く
{
  val:10570
  9737
  train:87599
  78685
  6000
  0.36869636616658863
  0.2063775967570529
  0.133824553207302
  0.09055310119681877
  7000
  0.3640534042527387
  0.2024536444218513
  0.13069366812041094
  0.08922714728875593
}


-overlap:オーバラップしていないものも含む
{
  val:10570
  10024
  train:87599
  81753
  0.35490593637131324
  0.19247020246941443
  0.12223150480960106
  0.08206431976612458
  -beam_size 3
  0.36389284042078746
  0.19556191563829126
  0.12306557484710942
  0.08141793460926491
}

-noninterro:疑問詞がないものも含む
{
  val:10570
  10270
  train:87599
  84365
  9500
  0.3689061536558604
  0.20711415393632365
  0.13572319383764175
  0.09340830219864989
  8500
  0.3605848002215529
  0.20136165336130474
  0.13075139460792767
  0.08934717916889375
  10000
  0.3482898660557566
  0.19104165741696685
  0.12325646936848747
  0.08324030642379629
  13000
  0.3546727016323772
  0.19729206924058848
  0.12703690987263444
  0.08592545606260674
}

コピーとカバレッジの追加
{
  5500
  0.36761840892680653
  0.22192467849212252
  0.154679173629004
  0.11291541501663589
}

duらのデータを使用
{
  5500
  0.37964762979441496
  0.21070869737860146
  0.1360045702569303
  0.09183197851379975
  7000
  0.39143732009863264
  0.22211157468158665
  0.14478863115254467
  0.0987884300592426

  enc_word_size 45000,dec 28000
  word_vec fix
  9000
  0.37964762979441496
  0.21070869737860146
  0.1360045702569303
  0.09183197851379975
}

疑問詞付きで実験
{
  <SEP> + 疑問詞で実験
  inputの辞書サイズは45000,outputは28000
  単語ベクトルは固定
  コピー、カバレッジはなし
  python preprocess.py \
  -train_src data/squad-src-train-interro.txt \
  -train_tgt data/squad-tgt-train.txt \
  -valid_src data/squad-src-val-interro.txt \
  -valid_tgt data/squad-tgt-val.txt \
  -save_data data/demo \
  -lower -src_vocab_size 45000 -tgt_vocab_size 28000

  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -gpu_ranks 3 -world_size 1
  12000
  0.42352199549253094
  0.29244977053327637
  0.21881937859302225
  0.16631600370337762
  9000
  0.4365445602660493
  0.30249012971662864
  0.22645192962571192
  0.17202424167198602
}

src_seq_sizeを100に変更し、データ数を増やした
{
  duらのデータを使用
  ここから、src_seq_size 100,tgt_seq_size 50、enc_voc_size 45000,dec_vocab_size 28000に固定
  データサイズ:62000->70000
  python preprocess.py \
  -train_src data/squad-src-train-du.txt \
  -train_tgt data/squad-tgt-train-du.txt \
  -valid_src data/squad-src-val-du.txt \
  -valid_tgt data/squad-tgt-val-du.txt \
  -save_data data/demo \
  -lower

  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -gpu_ranks 3 -world_size 1

  12000
  0.3818032773669874
  0.22207359215281677
  0.14836247284785528
  0.1038565408658504
  10000
  0.3797911121140998
  0.21980389442712892
  0.1454957579114939
  0.10071842183474895
}

全てのデータ
{
  overlap+noninterro
  sgdを使用
  python preprocess.py \
  -train_src data/squad-src-train-overlap-noninterro.txt \
  -train_tgt data/squad-tgt-train-overlap-noninterro.txt \
  -valid_src data/squad-src-val-overlap-noninterro.txt \
  -valid_tgt data/squad-tgt-val-overlap-noninterro.txt \
  -save_data data/demo \
  -lower \
  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -gpu_ranks 3 -world_size 1 \
  -optim sgd -learning_rate 1 -learning_rate_decay 0.5 -start_decay_steps 10000 -decay_steps 2000

  --beam_size 3
  18000
  0.37134221386631916
  0.2068268052269781
  0.13353502535049772
  0.09116215926940126
  -beam_size 5
  0.35703256254970045
  0.19998870428721507
  0.1303280621388004
  0.08979972747923132
  20500
  0.35238165102010544
  0.19838990179457527
  0.13000550458808965
  0.08987226052408974
}

shuffle
{
  データをpreprocessでシャッフル
  データはoverlap-noninterro
  13000
  0.35449933197783856
  0.19930672435560826
  0.13064106789167962
  0.09046163460412371

  duら
  stepsを25000に
  18000
  0.36857942154151785
  0.21345661038425523
  0.14225483513420595
  0.09894156819452919
  15000
  0.3830418887721869
  0.2242326172442351
  0.15009308209802488
  0.10519081126455221
  13000
  0.38603452563406127
  0.2231796731017263
  0.14824092517212442
  0.10281374896930358

  -start_decay_steps 20000 -decay_steps 2500 -train_steps 50000
  28000
  0.3988480580669166
  0.23560276332121058
  0.1585135752728077
  0.1114058235070068
  37000
  0.39658456174426027
  0.2358171198938562
  0.16000026399319953
  0.11342067478486642
  38000
  0.39549555475888737
  0.2352811643317181
  0.15972696221112345
  0.11339629816619744

  -start_decay_steps 20000 -decay_steps 3000 -train_steps 60000
  30000
  0.400140624537702
  0.23731986280714962
  0.1601483527090614
  0.1127673503484243
  41000
  0.40016893254925556
  0.23866364072141835
  0.16182145550580126
  0.11443930570133387
  qgevalcap/eval.py
  Bleu_1: 0.41161
  Bleu_2: 0.24549
  Bleu_3: 0.16618
  Bleu_4: 0.11771

  -optim sgd -learning_rate 1 -learning_rate_decay 0.5 -start_decay_steps 20000 -decay_steps 2000 -train_steps 60000
  27000
  0.3935429317536642
  0.23440159835834948
  0.1591811646641791
  0.11273642282453042
  30000
  0.3967899897331695
  0.2362346318980176
  0.1599417471152941
  0.11286157890117823
}

gru
{
  gruを使用、sgdは相性が悪いため、adamを使用
  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -rnn_type GRU \
  -gpu_ranks 3 -world_size 1 \
  -train_steps 30000
  スコアはとても低い
}

bridge
{
  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -gpu_ranks 3 -world_size 1 \
  -bridge \
  -optim sgd -learning_rate 1 -learning_rate_decay 0.5 -start_decay_steps 20000 -decay_steps 3000 -train_steps 50000
  26000
  0.38182877287214717
  0.22205685359382502
  0.14773142620211194
  0.10315436253715742
  44000
  0.3953961968128539
  0.2313639103813019
  0.15466326394909802
  0.1078724355523195
}


transformerで実験
コピーとカバレッジそれぞれで実験
answerを付け加えて実験
interroを,,
