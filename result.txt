文そのまま（答えや疑問詞など含めず）
質問文の文字数が5以下のノイズデータは省いたが、それ以外の文は全て使用した。
50文字までを訓練に使用

全ての文
0.40700896414178056
0.23134561150951782
0.15074457485064752
0.10203992991167184
->論文とほぼ同じスコア

Duらの論文を参考に、内容語の重複がないものを取り除く
疑問詞がないものも取り除く
{
  val:10570
  9737
  train:87599
  78685
  6000
  0.36869636616658863
  0.2063775967570529
  0.133824553207302
  0.09055310119681877
  7000
  0.3640534042527387
  0.2024536444218513
  0.13069366812041094
  0.08922714728875593
}


-overlap:オーバラップしていないものも含む
{
  val:10570
  10024
  train:87599
  81753
  0.35490593637131324
  0.19247020246941443
  0.12223150480960106
  0.08206431976612458
  -beam_size 3
  0.36389284042078746
  0.19556191563829126
  0.12306557484710942
  0.08141793460926491
}

-noninterro:疑問詞がないものも含む
{
  val:10570
  10270
  train:87599
  84365
  9500
  0.3689061536558604
  0.20711415393632365
  0.13572319383764175
  0.09340830219864989
  8500
  0.3605848002215529
  0.20136165336130474
  0.13075139460792767
  0.08934717916889375
  10000
  0.3482898660557566
  0.19104165741696685
  0.12325646936848747
  0.08324030642379629
  13000
  0.3546727016323772
  0.19729206924058848
  0.12703690987263444
  0.08592545606260674
}

コピーとカバレッジの追加
{
  5500
  0.36761840892680653
  0.22192467849212252
  0.154679173629004
  0.11291541501663589
}

duらのデータを使用
{
  5500
  0.37964762979441496
  0.21070869737860146
  0.1360045702569303
  0.09183197851379975
  7000
  0.39143732009863264
  0.22211157468158665
  0.14478863115254467
  0.0987884300592426

  enc_word_size 45000,dec 28000
  word_vec fix
  9000
  0.37964762979441496
  0.21070869737860146
  0.1360045702569303
  0.09183197851379975
}

疑問詞付きで実験
{
  <SEP> + 疑問詞で実験
  inputの辞書サイズは45000,outputは28000
  単語ベクトルは固定
  コピー、カバレッジはなし
  python preprocess.py \
  -train_src data/squad-src-train-interro.txt \
  -train_tgt data/squad-tgt-train.txt \
  -valid_src data/squad-src-val-interro.txt \
  -valid_tgt data/squad-tgt-val.txt \
  -save_data data/demo \
  -lower -src_vocab_size 45000 -tgt_vocab_size 28000

  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -gpu_ranks 3 -world_size 1
  12000
  0.42352199549253094
  0.29244977053327637
  0.21881937859302225
  0.16631600370337762
  9000
  0.4365445602660493
  0.30249012971662864
  0.22645192962571192
  0.17202424167198602
}

src_seq_sizeを100に変更し、データ数を増やした
{
  duらのデータを使用
  ここから、src_seq_size 100,tgt_seq_size 50、enc_voc_size 45000,dec_vocab_size 28000に固定
  データサイズ:62000->70000
  python preprocess.py \
  -train_src data/squad-src-train-du.txt \
  -train_tgt data/squad-tgt-train-du.txt \
  -valid_src data/squad-src-val-du.txt \
  -valid_tgt data/squad-tgt-val-du.txt \
  -save_data data/demo \
  -lower

  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -gpu_ranks 3 -world_size 1

  12000
  0.3818032773669874
  0.22207359215281677
  0.14836247284785528
  0.1038565408658504
  10000
  0.3797911121140998
  0.21980389442712892
  0.1454957579114939
  0.10071842183474895
}

全てのデータ
{
  overlap+noninterro
  sgdを使用
  python preprocess.py \
  -train_src data/squad-src-train-overlap-noninterro.txt \
  -train_tgt data/squad-tgt-train-overlap-noninterro.txt \
  -valid_src data/squad-src-val-overlap-noninterro.txt \
  -valid_tgt data/squad-tgt-val-overlap-noninterro.txt \
  -save_data data/demo \
  -lower \
  python3 train.py \
  -data data/demo \
  -save_model model_data/demo-model \
  -pre_word_vecs_enc "data/embeddings.enc.pt" -pre_word_vecs_dec "data/embeddings.dec.pt" \
  -fix_word_vecs_enc -fix_word_vecs_dec \
  -gpu_ranks 3 -world_size 1 \
  -optim sgd -learning_rate 1 -learning_rate_decay 0.5 -start_decay_steps 10000 -decay_steps 2000

  --beam_size 3
  18000
  0.37134221386631916
  0.2068268052269781
  0.13353502535049772
  0.09116215926940126
  -beam_size 5
  0.35703256254970045
  0.19998870428721507
  0.1303280621388004
  0.08979972747923132
  20500
  0.35238165102010544
  0.19838990179457527
  0.13000550458808965
  0.08987226052408974
}

transformerで実験
ベースを12ポイントになるように調整
コピーとカバレッジそれぞれで実験
answerを付け加えて実験
