[2019-04-09 16:46:37,136 INFO] Extracting features...
[2019-04-09 16:46:37,137 INFO]  * number of source features: 0.
[2019-04-09 16:46:37,137 INFO]  * number of target features: 0.
[2019-04-09 16:46:37,137 INFO] Building `Fields` object...
[2019-04-09 16:46:37,137 INFO] Building & saving training data...
[2019-04-09 16:46:37,137 INFO] Reading source and target files: data/fra_train.txt data/eng_train.txt.
[2019-04-09 16:46:37,186 INFO] Building shard 0.
[2019-04-09 16:46:39,591 INFO]  * saving 0th train data shard to data/demo.train.0.pt.
[2019-04-09 16:46:42,291 INFO] Building & saving validation data...
[2019-04-09 16:46:42,292 INFO] Reading source and target files: data/fra_val.txt data/eng_val.txt.
[2019-04-09 16:46:42,302 INFO] Building shard 0.
[2019-04-09 16:46:42,551 INFO]  * saving 0th valid data shard to data/demo.valid.0.pt.
[2019-04-09 16:46:42,847 INFO] Building & saving vocabulary...
[2019-04-09 16:46:43,869 INFO]  * reloading data/demo.train.0.pt.
[2019-04-09 16:46:45,231 INFO]  * tgt vocab size: 24174.
[2019-04-09 16:46:45,317 INFO]  * src vocab size: 39207.
[2019-04-09 16:48:54,558 INFO] Extracting features...
[2019-04-09 16:48:54,558 INFO]  * number of source features: 0.
[2019-04-09 16:48:54,558 INFO]  * number of target features: 0.
[2019-04-09 16:48:54,558 INFO] Building `Fields` object...
[2019-04-09 16:48:54,558 INFO] Building & saving training data...
[2019-04-09 16:48:54,558 INFO] Reading source and target files: data/squad-src-train.txt data/squad-tgt-train.txt.
[2019-04-09 16:48:54,610 INFO] Building shard 0.
[2019-04-09 16:48:57,077 INFO]  * saving 0th train data shard to data/demo.train.0.pt.
[2019-04-09 16:49:00,788 INFO] Building & saving validation data...
[2019-04-09 16:49:00,788 INFO] Reading source and target files: data/squad-src-val.txt data/squad-tgt-val.txt.
[2019-04-09 16:49:00,790 INFO] Building shard 0.
[2019-04-09 16:49:00,888 INFO]  * saving 0th valid data shard to data/demo.valid.0.pt.
[2019-04-09 16:49:01,143 INFO] Building & saving vocabulary...
[2019-04-09 16:49:02,262 INFO]  * reloading data/demo.train.0.pt.
[2019-04-09 16:49:03,566 INFO]  * tgt vocab size: 36176.
[2019-04-09 16:49:03,717 INFO]  * src vocab size: 50002.
[2019-04-11 14:03:31,289 INFO]  * src vocab size = 50002
[2019-04-11 14:03:31,290 INFO]  * tgt vocab size = 36176
[2019-04-11 14:03:31,290 INFO] Building model...
[2019-04-11 14:03:32,309 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(50002, 300, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(300, 300, num_layers=2, dropout=0.3, bidirectional=True)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(36176, 300, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3)
      (layers): ModuleList(
        (0): LSTMCell(900, 600)
        (1): LSTMCell(600, 600)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=600, out_features=600, bias=False)
      (linear_out): Linear(in_features=1200, out_features=600, bias=False)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=600, out_features=36176, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-04-11 14:03:32,310 INFO] encoder: 18610200
[2019-04-11 14:03:32,310 INFO] decoder: 40164176
[2019-04-11 14:03:32,310 INFO] * number of parameters: 58774376
[2019-04-11 14:03:32,317 INFO] Starting training on CPU, could be very slow
[2019-04-11 14:03:32,317 INFO] Start training loop and validate every 500 steps...
[2019-04-11 14:03:33,691 INFO] Loading dataset from data/demo.train.0.pt, number of examples: 74622
[2019-04-11 14:04:25,204 INFO]  * src vocab size = 50002
[2019-04-11 14:04:25,204 INFO]  * tgt vocab size = 36176
[2019-04-11 14:04:25,204 INFO] Building model...
[2019-04-11 14:04:26,251 INFO] NMTModel(
  (encoder): RNNEncoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(50002, 300, padding_idx=1)
        )
      )
    )
    (rnn): LSTM(300, 300, num_layers=2, dropout=0.3, bidirectional=True)
  )
  (decoder): InputFeedRNNDecoder(
    (embeddings): Embeddings(
      (make_embedding): Sequential(
        (emb_luts): Elementwise(
          (0): Embedding(36176, 300, padding_idx=1)
        )
      )
    )
    (dropout): Dropout(p=0.3)
    (rnn): StackedLSTM(
      (dropout): Dropout(p=0.3)
      (layers): ModuleList(
        (0): LSTMCell(900, 600)
        (1): LSTMCell(600, 600)
      )
    )
    (attn): GlobalAttention(
      (linear_in): Linear(in_features=600, out_features=600, bias=False)
      (linear_out): Linear(in_features=1200, out_features=600, bias=False)
    )
  )
  (generator): Sequential(
    (0): Linear(in_features=600, out_features=36176, bias=True)
    (1): Cast()
    (2): LogSoftmax()
  )
)
[2019-04-11 14:04:26,252 INFO] encoder: 18610200
[2019-04-11 14:04:26,252 INFO] decoder: 40164176
[2019-04-11 14:04:26,252 INFO] * number of parameters: 58774376
[2019-04-11 14:04:26,257 INFO] Starting training on CPU, could be very slow
[2019-04-11 14:04:26,257 INFO] Start training loop and validate every 500 steps...
[2019-04-11 14:04:27,410 INFO] Loading dataset from data/demo.train.0.pt, number of examples: 74622
